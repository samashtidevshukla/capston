{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import itertools \n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/samashtishukla/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/samashtishukla/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('sample30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AV13O1A8GV-KLJ3akUyj</td>\n",
       "      <td>Universal Music</td>\n",
       "      <td>Movies, Music &amp; Books,Music,R&amp;b,Movies &amp; TV,Mo...</td>\n",
       "      <td>Universal Music Group / Cash Money</td>\n",
       "      <td>Pink Friday: Roman Reloaded Re-Up (w/dvd)</td>\n",
       "      <td>2012-11-30T06:21:45.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this album. it's very good. more to the...</td>\n",
       "      <td>Just Awesome</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor. This review was collected as part...</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AV14LG0R-jtxr-f38QfS</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Food,Packaged Foods,Snacks,Crackers,Snacks, Co...</td>\n",
       "      <td>Lundberg</td>\n",
       "      <td>Lundberg Organic Cinnamon Toast Rice Cakes</td>\n",
       "      <td>2017-07-09T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Good flavor.</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dorothy w</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-01-06T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>I read through the reviews on here before look...</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rebecca</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AV16khLE-jtxr-f38VFn</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>Personal Care,Medicine Cabinet,Lubricant/Sperm...</td>\n",
       "      <td>K-Y</td>\n",
       "      <td>K-Y Love Sensuality Pleasure Gel</td>\n",
       "      <td>2016-12-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>My husband bought this gel for us. The gel cau...</td>\n",
       "      <td>Irritation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walker557</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id            brand  \\\n",
       "0  AV13O1A8GV-KLJ3akUyj  Universal Music   \n",
       "1  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "2  AV14LG0R-jtxr-f38QfS         Lundberg   \n",
       "3  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "4  AV16khLE-jtxr-f38VFn              K-Y   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Movies, Music & Books,Music,R&b,Movies & TV,Mo...   \n",
       "1  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "2  Food,Packaged Foods,Snacks,Crackers,Snacks, Co...   \n",
       "3  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "4  Personal Care,Medicine Cabinet,Lubricant/Sperm...   \n",
       "\n",
       "                         manufacturer  \\\n",
       "0  Universal Music Group / Cash Money   \n",
       "1                            Lundberg   \n",
       "2                            Lundberg   \n",
       "3                                 K-Y   \n",
       "4                                 K-Y   \n",
       "\n",
       "                                         name              reviews_date  \\\n",
       "0   Pink Friday: Roman Reloaded Re-Up (w/dvd)  2012-11-30T06:21:45.000Z   \n",
       "1  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "2  Lundberg Organic Cinnamon Toast Rice Cakes  2017-07-09T00:00:00.000Z   \n",
       "3            K-Y Love Sensuality Pleasure Gel  2016-01-06T00:00:00.000Z   \n",
       "4            K-Y Love Sensuality Pleasure Gel  2016-12-21T00:00:00.000Z   \n",
       "\n",
       "  reviews_didPurchase reviews_doRecommend  reviews_rating  \\\n",
       "0                 NaN                 NaN               5   \n",
       "1                True                 NaN               5   \n",
       "2                True                 NaN               5   \n",
       "3               False               False               1   \n",
       "4               False               False               1   \n",
       "\n",
       "                                        reviews_text reviews_title  \\\n",
       "0  i love this album. it's very good. more to the...  Just Awesome   \n",
       "1  Good flavor. This review was collected as part...          Good   \n",
       "2                                       Good flavor.          Good   \n",
       "3  I read through the reviews on here before look...  Disappointed   \n",
       "4  My husband bought this gel for us. The gel cau...    Irritation   \n",
       "\n",
       "  reviews_userCity reviews_userProvince reviews_username user_sentiment  \n",
       "0      Los Angeles                  NaN           joshua       Positive  \n",
       "1              NaN                  NaN        dorothy w       Positive  \n",
       "2              NaN                  NaN        dorothy w       Positive  \n",
       "3              NaN                  NaN          rebecca       Negative  \n",
       "4              NaN                  NaN        walker557       Negative  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          0\n",
       "brand                       0\n",
       "categories                  0\n",
       "manufacturer              141\n",
       "name                        0\n",
       "reviews_date               46\n",
       "reviews_didPurchase     14068\n",
       "reviews_doRecommend      2570\n",
       "reviews_rating              0\n",
       "reviews_text                0\n",
       "reviews_title             190\n",
       "reviews_userCity        28071\n",
       "reviews_userProvince    29830\n",
       "reviews_username           63\n",
       "user_sentiment              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews_date</th>\n",
       "      <th>reviews_didPurchase</th>\n",
       "      <th>reviews_doRecommend</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_userCity</th>\n",
       "      <th>reviews_userProvince</th>\n",
       "      <th>reviews_username</th>\n",
       "      <th>user_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29990</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2016-12-26T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>This whole set of these (mask, shampoo and con...</td>\n",
       "      <td>Smells Amazing!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>emily646</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29991</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-07T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>Took the 48 hour hair challenge using the sham...</td>\n",
       "      <td>Great clay products!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meganjoywolfe</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29992</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2016-12-16T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love the smell of this product! I...</td>\n",
       "      <td>Smells Amazing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kjb2205</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29993</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-23T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I seriously was so surprised after my shower h...</td>\n",
       "      <td>Ends feel so soft!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maryyyyyalice</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29994</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-14T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I got to try this conditioner for free and boy...</td>\n",
       "      <td>By far, my new favorite conditioner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smartthunny</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29995</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-23T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I got this conditioner with Influenster to try...</td>\n",
       "      <td>Softness!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>laurasnchz</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29996</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-27T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I love it , I received this for review purpose...</td>\n",
       "      <td>I love it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scarlepadilla</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29997</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-21T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>First of all I love the smell of this product....</td>\n",
       "      <td>Hair is so smooth after use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liviasuexo</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29998</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-11T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I received this through Influenster and will n...</td>\n",
       "      <td>Perfect for my oily hair!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ktreed95</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29999</td>\n",
       "      <td>AVpfW8y_LJeJML437ySW</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>Beauty,Hair Care,Shampoo &amp; Conditioner,Holiday...</td>\n",
       "      <td>L'oreal Paris</td>\n",
       "      <td>L'or233al Paris Elvive Extraordinary Clay Reba...</td>\n",
       "      <td>2017-01-19T00:00:00.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>I received this product complimentary from inf...</td>\n",
       "      <td>Conditioned into healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kcoopxoxo</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id          brand  \\\n",
       "29990  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "29991  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "29992  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "29993  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "29994  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "29995  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "29996  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "29997  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "29998  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "29999  AVpfW8y_LJeJML437ySW  L'oreal Paris   \n",
       "\n",
       "                                              categories   manufacturer  \\\n",
       "29990  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "29991  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "29992  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "29993  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "29994  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "29995  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "29996  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "29997  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "29998  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "29999  Beauty,Hair Care,Shampoo & Conditioner,Holiday...  L'oreal Paris   \n",
       "\n",
       "                                                    name  \\\n",
       "29990  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29991  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29992  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29993  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29994  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29995  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29996  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29997  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29998  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "29999  L'or233al Paris Elvive Extraordinary Clay Reba...   \n",
       "\n",
       "                   reviews_date reviews_didPurchase reviews_doRecommend  \\\n",
       "29990  2016-12-26T00:00:00.000Z               False                True   \n",
       "29991  2017-01-07T00:00:00.000Z               False                True   \n",
       "29992  2016-12-16T00:00:00.000Z               False                True   \n",
       "29993  2017-01-23T00:00:00.000Z               False                True   \n",
       "29994  2017-01-14T00:00:00.000Z               False                True   \n",
       "29995  2017-01-23T00:00:00.000Z               False                True   \n",
       "29996  2017-01-27T00:00:00.000Z               False                True   \n",
       "29997  2017-01-21T00:00:00.000Z               False                True   \n",
       "29998  2017-01-11T00:00:00.000Z               False                True   \n",
       "29999  2017-01-19T00:00:00.000Z               False                True   \n",
       "\n",
       "       reviews_rating                                       reviews_text  \\\n",
       "29990               5  This whole set of these (mask, shampoo and con...   \n",
       "29991               5  Took the 48 hour hair challenge using the sham...   \n",
       "29992               5  I absolutely love the smell of this product! I...   \n",
       "29993               5  I seriously was so surprised after my shower h...   \n",
       "29994               5  I got to try this conditioner for free and boy...   \n",
       "29995               5  I got this conditioner with Influenster to try...   \n",
       "29996               5  I love it , I received this for review purpose...   \n",
       "29997               5  First of all I love the smell of this product....   \n",
       "29998               5  I received this through Influenster and will n...   \n",
       "29999               5  I received this product complimentary from inf...   \n",
       "\n",
       "                             reviews_title reviews_userCity  \\\n",
       "29990                      Smells Amazing!              NaN   \n",
       "29991                 Great clay products!              NaN   \n",
       "29992                       Smells Amazing              NaN   \n",
       "29993                   Ends feel so soft!              NaN   \n",
       "29994  By far, my new favorite conditioner              NaN   \n",
       "29995                           Softness!!              NaN   \n",
       "29996                            I love it              NaN   \n",
       "29997          Hair is so smooth after use              NaN   \n",
       "29998            Perfect for my oily hair!              NaN   \n",
       "29999             Conditioned into healthy              NaN   \n",
       "\n",
       "      reviews_userProvince reviews_username user_sentiment  \n",
       "29990                  NaN         emily646       Positive  \n",
       "29991                  NaN    meganjoywolfe       Positive  \n",
       "29992                  NaN          kjb2205       Positive  \n",
       "29993                  NaN    maryyyyyalice       Positive  \n",
       "29994                  NaN      smartthunny       Positive  \n",
       "29995                  NaN       laurasnchz       Positive  \n",
       "29996                  NaN    scarlepadilla       Positive  \n",
       "29997                  NaN       liviasuexo       Positive  \n",
       "29998                  NaN         ktreed95       Positive  \n",
       "29999                  NaN        kcoopxoxo       Positive  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['reviews_title'] = master_df['reviews_title'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.DataFrame()\n",
    "Product_review_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating review title and review text\n",
    "Product_review_df['comb_review'] = master_df['reviews_title'].str.lower() + ' ' + master_df['reviews_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_review_df['user_sentiment_code'] = master_df['user_sentiment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_review_df['product_name'] = master_df['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = Product_review_df[[\"comb_review\",\"user_sentiment_code\"]]\n",
    "review_df = selected_columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    26632\n",
       "negative     3367\n",
       "Name: user_sentiment_code, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product_review_df['user_sentiment_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comb_review</th>\n",
       "      <th>user_sentiment_code</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>just awesome i love this album. it's very good...</td>\n",
       "      <td>positive</td>\n",
       "      <td>pink friday: roman reloaded re-up (w/dvd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>good good flavor. this review was collected as...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lundberg organic cinnamon toast rice cakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>good good flavor.</td>\n",
       "      <td>positive</td>\n",
       "      <td>lundberg organic cinnamon toast rice cakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>disappointed i read through the reviews on her...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>irritation my husband bought this gel for us. ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comb_review user_sentiment_code  \\\n",
       "0  just awesome i love this album. it's very good...            positive   \n",
       "1  good good flavor. this review was collected as...            positive   \n",
       "2                                  good good flavor.            positive   \n",
       "3  disappointed i read through the reviews on her...            negative   \n",
       "4  irritation my husband bought this gel for us. ...            negative   \n",
       "\n",
       "                                 product_name  \n",
       "0   pink friday: roman reloaded re-up (w/dvd)  \n",
       "1  lundberg organic cinnamon toast rice cakes  \n",
       "2  lundberg organic cinnamon toast rice cakes  \n",
       "3            k-y love sensuality pleasure gel  \n",
       "4            k-y love sensuality pleasure gel  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product_review_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comb_review</th>\n",
       "      <th>user_sentiment_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>just awesome i love this album. it's very good...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>good good flavor. this review was collected as...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>good good flavor.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>disappointed i read through the reviews on her...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>irritation my husband bought this gel for us. ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comb_review user_sentiment_code\n",
       "0  just awesome i love this album. it's very good...            positive\n",
       "1  good good flavor. this review was collected as...            positive\n",
       "2                                  good good flavor.            positive\n",
       "3  disappointed i read through the reviews on her...            negative\n",
       "4  irritation my husband bought this gel for us. ...            negative"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df[review_df['user_sentiment_code'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    26632\n",
       "negative     3367\n",
       "Name: user_sentiment_code, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['user_sentiment_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['user_sentiment_code'] = review_df['user_sentiment_code'].map(lambda x: 1 if x=='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comb_review</th>\n",
       "      <th>user_sentiment_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>just awesome i love this album. it's very good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>good good flavor. this review was collected as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>good good flavor.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>disappointed i read through the reviews on her...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>irritation my husband bought this gel for us. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comb_review  user_sentiment_code\n",
       "0  just awesome i love this album. it's very good...                    1\n",
       "1  good good flavor. this review was collected as...                    1\n",
       "2                                  good good flavor.                    1\n",
       "3  disappointed i read through the reviews on her...                    0\n",
       "4  irritation my husband bought this gel for us. ...                    0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29999"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29999, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comb_review            0\n",
       "user_sentiment_code    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning Data\n",
    "def cleanData(text, lowercase = True, remove_stops = False, stemming = True, lemmatization = True):\n",
    "    txt = str(text)\n",
    "    \n",
    "    # Replace apostrophes with standard lexicons\n",
    "    txt = txt.replace(\"isn't\", \"is not\")\n",
    "    txt = txt.replace(\"aren't\", \"are not\")\n",
    "    txt = txt.replace(\"ain't\", \"am not\")\n",
    "    txt = txt.replace(\"won't\", \"will not\")\n",
    "    txt = txt.replace(\"didn't\", \"did not\")\n",
    "    txt = txt.replace(\"shan't\", \"shall not\")\n",
    "    txt = txt.replace(\"haven't\", \"have not\")\n",
    "    txt = txt.replace(\"hadn't\", \"had not\")\n",
    "    txt = txt.replace(\"hasn't\", \"has not\")\n",
    "    txt = txt.replace(\"don't\", \"do not\")\n",
    "    txt = txt.replace(\"wasn't\", \"was not\")\n",
    "    txt = txt.replace(\"weren't\", \"were not\")\n",
    "    txt = txt.replace(\"doesn't\", \"does not\")\n",
    "    txt = txt.replace(\"'s\", \" is\")\n",
    "    txt = txt.replace(\"'re\", \" are\")\n",
    "    txt = txt.replace(\"'m\", \" am\")\n",
    "    txt = txt.replace(\"'d\", \" would\")\n",
    "    txt = txt.replace(\"'ll\", \" will\")\n",
    "    \n",
    "    # More cleaning\n",
    "    txt = re.sub(r\"review\", \"\", txt)\n",
    "    txt = re.sub(r\"Review\", \"\", txt)\n",
    "    txt = re.sub(r\"TripAdvisor\", \"\", txt)\n",
    "    txt = re.sub(r\"reviews\", \"\", txt)\n",
    "    txt = re.sub(r\"Hotel\", \"\", txt)\n",
    "    txt = re.sub(r\"what's\", \"\", txt)\n",
    "    txt = re.sub(r\"What's\", \"\", txt)\n",
    "    txt = re.sub(r\"\\'s\", \" \", txt)\n",
    "    txt = txt.replace(\"pic\", \"picture\")\n",
    "    txt = re.sub(r\"\\'ve\", \" have \", txt)\n",
    "    txt = re.sub(r\"can't\", \"cannot \", txt)\n",
    "    txt = re.sub(r\"n't\", \" not \", txt)\n",
    "    txt = re.sub(r\"I'm\", \"I am\", txt)\n",
    "    txt = re.sub(r\" m \", \" am \", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are \", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would \", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will \", txt)\n",
    "    txt = re.sub(r\" e g \", \" eg \", txt)\n",
    "\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    #txt = ''.join([c for c in text if c not in punctuation])\n",
    "    txt = txt.replace(\".\", \" \")\n",
    "    txt = txt.replace(\":\", \" \")\n",
    "    txt = txt.replace(\"!\", \" \")\n",
    "    txt = txt.replace(\"&\", \" \")\n",
    "    txt = txt.replace(\"#\", \" \")\n",
    "    \n",
    "    # Remove all symbols\n",
    "    txt = re.sub(r'[^A-Za-z0-9\\s]',r' ',txt)\n",
    "    txt = re.sub(r'\\n',r' ',txt)\n",
    "    \n",
    "    txt = re.sub(r'[0-9]',r' ',txt)\n",
    "    \n",
    "    # Replace words like sooooooo with so\n",
    "    txt = ''.join(''.join(s)[:2] for _, s in itertools.groupby(txt))\n",
    "    \n",
    "    # Split attached words\n",
    "    #txt = \" \".join(re.findall('[A-Z][^A-Z]*', txt))   \n",
    "    \n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "        \n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "#         print (len(txt.split()))\n",
    "#         print (txt)\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "    \n",
    "    if lemmatization:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w, pos='v') for w in txt.split()])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my test soo do not\n"
     ]
    }
   ],
   "source": [
    "testdata = cleanData(\"My test sooooooo didn't !\")\n",
    "print(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the review\n",
    "review_df['comb_review'] = review_df['comb_review'].map(lambda x: cleanData(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29999"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf = True,lowercase = True, strip_accents='ascii',stop_words=stopset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(review_df.comb_review)\n",
    "y = review_df.user_sentiment_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('transform.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29999, 11952)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29999,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: user_sentiment_code, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    26632\n",
       "0     3367\n",
       "Name: user_sentiment_code, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29999, 2)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.30,random_state=42,stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20999, 11952)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20999, 11952)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 11952)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7990\n",
       "0    1010\n",
       "Name: user_sentiment_code, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18642\n",
       "0     2357\n",
       "Name: user_sentiment_code, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class imbalance technique\n",
    "smt = SMOTE()\n",
    "X_train_sm,y_train_sm = smt.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37284,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37284, 11952)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = naive_bayes.BernoulliNB()\n",
    "clf = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8639459021858183"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8158888888888889"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 608,  402],\n",
       "       [1255, 6735]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.890460765518609"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samashtishukla/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8952807276536978"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,logisticRegr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,logisticRegr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111273112863675"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,logisticRegr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforestRegr = RandomForestClassifier(n_estimators =100,min_samples_split =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=4,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforestRegr.fit(X_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,randomforestRegr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981111111111111"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,randomforestRegr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9438147172354636"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,randomforestRegr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samashtishukla/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:55:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=1, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbRegr=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "xgbRegr.fit(X_train_sm,y_train_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7787777777777778"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbRegr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7787777777777778"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,xgbRegr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8653729122996823"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,xgbRegr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Random Forest as best model. Pickling this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'nlp_model.pkl'\n",
    "pickle.dump(randomforestRegr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comb_review</th>\n",
       "      <th>user_sentiment_code</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>just awesome i love this album. it's very good...</td>\n",
       "      <td>positive</td>\n",
       "      <td>pink friday: roman reloaded re-up (w/dvd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>good good flavor. this review was collected as...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lundberg organic cinnamon toast rice cakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>good good flavor.</td>\n",
       "      <td>positive</td>\n",
       "      <td>lundberg organic cinnamon toast rice cakes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>disappointed i read through the reviews on her...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>irritation my husband bought this gel for us. ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comb_review user_sentiment_code  \\\n",
       "0  just awesome i love this album. it's very good...            positive   \n",
       "1  good good flavor. this review was collected as...            positive   \n",
       "2                                  good good flavor.            positive   \n",
       "3  disappointed i read through the reviews on her...            negative   \n",
       "4  irritation my husband bought this gel for us. ...            negative   \n",
       "\n",
       "                                 product_name  \n",
       "0   pink friday: roman reloaded re-up (w/dvd)  \n",
       "1  lundberg organic cinnamon toast rice cakes  \n",
       "2  lundberg organic cinnamon toast rice cakes  \n",
       "3            k-y love sensuality pleasure gel  \n",
       "4            k-y love sensuality pleasure gel  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product_review_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_comb_review = Product_review_df.loc[Product_review_df['product_name']==\"k-y love sensuality pleasure gel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comb_review</th>\n",
       "      <th>user_sentiment_code</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>disappointed i read through the reviews on her...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>irritation my husband bought this gel for us. ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>not worth it my boyfriend and i bought this to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>disappointing bought this earlier today and wa...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>not happy at all i bought this product for my ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>very disappointing my husband and i bought thi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>don't buy got as a surprise for my husband the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>pretty dissapoitned tried it with my husband a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>waste of money purchased this thinking it woul...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>waste of money bought this to enhance our time...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>not happy with this product i bought this afte...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>disappointed first time purchase of this type ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>not what i expected i bought this and tried th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>was so disappointed!! i bought this product to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>very disappointed! i bought this to try to spi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>pretty nice i bought this because it had bette...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>first time using it was my first time using k-...</td>\n",
       "      <td>negative</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>we love it! i noticed this product on clearanc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>good times i used this product a couple of tim...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>does the job used a few times stays a bit stic...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>loved loved this review was collected as part ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>great sensation this is a good product. will g...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>that little extra something.. i really enjoyed...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>great product! awesome product for couples. it...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>why wouldn't you try it exceptional product, t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>amazing! i used this for the first time with m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>amazing great product! exactly what it says wo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>k-y love sensuality pleasure gel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comb_review user_sentiment_code  \\\n",
       "3   disappointed i read through the reviews on her...            negative   \n",
       "4   irritation my husband bought this gel for us. ...            negative   \n",
       "5   not worth it my boyfriend and i bought this to...            negative   \n",
       "6   disappointing bought this earlier today and wa...            negative   \n",
       "7   not happy at all i bought this product for my ...            negative   \n",
       "8   very disappointing my husband and i bought thi...            negative   \n",
       "9   don't buy got as a surprise for my husband the...            positive   \n",
       "10  pretty dissapoitned tried it with my husband a...            negative   \n",
       "11  waste of money purchased this thinking it woul...            positive   \n",
       "12  waste of money bought this to enhance our time...            negative   \n",
       "13  not happy with this product i bought this afte...            negative   \n",
       "14  disappointed first time purchase of this type ...            positive   \n",
       "15  not what i expected i bought this and tried th...            negative   \n",
       "16  was so disappointed!! i bought this product to...            negative   \n",
       "17  very disappointed! i bought this to try to spi...            negative   \n",
       "18  pretty nice i bought this because it had bette...            positive   \n",
       "19  first time using it was my first time using k-...            negative   \n",
       "20  we love it! i noticed this product on clearanc...            positive   \n",
       "21  good times i used this product a couple of tim...            positive   \n",
       "22  does the job used a few times stays a bit stic...            positive   \n",
       "23  loved loved this review was collected as part ...            positive   \n",
       "24  great sensation this is a good product. will g...            positive   \n",
       "25  that little extra something.. i really enjoyed...            positive   \n",
       "26  great product! awesome product for couples. it...            positive   \n",
       "27  why wouldn't you try it exceptional product, t...            positive   \n",
       "28  amazing! i used this for the first time with m...            positive   \n",
       "29  amazing great product! exactly what it says wo...            positive   \n",
       "\n",
       "                        product_name  \n",
       "3   k-y love sensuality pleasure gel  \n",
       "4   k-y love sensuality pleasure gel  \n",
       "5   k-y love sensuality pleasure gel  \n",
       "6   k-y love sensuality pleasure gel  \n",
       "7   k-y love sensuality pleasure gel  \n",
       "8   k-y love sensuality pleasure gel  \n",
       "9   k-y love sensuality pleasure gel  \n",
       "10  k-y love sensuality pleasure gel  \n",
       "11  k-y love sensuality pleasure gel  \n",
       "12  k-y love sensuality pleasure gel  \n",
       "13  k-y love sensuality pleasure gel  \n",
       "14  k-y love sensuality pleasure gel  \n",
       "15  k-y love sensuality pleasure gel  \n",
       "16  k-y love sensuality pleasure gel  \n",
       "17  k-y love sensuality pleasure gel  \n",
       "18  k-y love sensuality pleasure gel  \n",
       "19  k-y love sensuality pleasure gel  \n",
       "20  k-y love sensuality pleasure gel  \n",
       "21  k-y love sensuality pleasure gel  \n",
       "22  k-y love sensuality pleasure gel  \n",
       "23  k-y love sensuality pleasure gel  \n",
       "24  k-y love sensuality pleasure gel  \n",
       "25  k-y love sensuality pleasure gel  \n",
       "26  k-y love sensuality pleasure gel  \n",
       "27  k-y love sensuality pleasure gel  \n",
       "28  k-y love sensuality pleasure gel  \n",
       "29  k-y love sensuality pleasure gel  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_comb_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-208-d9e938fffa52>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-208-d9e938fffa52>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    getFeatureExtract(fetch_comb_review):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "getFeatureExtract(fetch_comb_review):\n",
    "    vectorizer = TfidfVectorizer(use_idf = True,lowercase = True, strip_accents='ascii',stop_words=stopset)\n",
    "    X = vectorizer.fit_transform(fetch_comb_review.comb_review)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-209-3123b990fc69>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-209-3123b990fc69>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    getPrediction(product_name):\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def getPrediction(product_name):\n",
    "    \n",
    "    fetch_comb_review = Product_review_df.loc[Product_review_df['product_name']==product_name]\n",
    "    X = getFeatureExtract(fetch_comb_review)\n",
    "    randomforestRegr.predict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpmodel = pickle.load(open(\"nlp_model.pkl\", 'rb'))\n",
    "\n",
    "# Create new tfidfVectorizer with old vocabulary\n",
    "#tf1_new = TfidfVectorizer(analyzer='word', ngram_range=(1,2), stop_words = \"english\", lowercase = True,\n",
    " #                         max_features = 500000, vocabulary = tf1.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(\"transform.pkl\", 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Sentiment(product_name):\n",
    "    fetch_comb_review = Product_review_df.loc[Product_review_df['product_name']==product_name]\n",
    "    print(fetch_comb_review.head())\n",
    "    movie_vector = vectorizer.transform(fetch_comb_review.comb_review)\n",
    "    pred = nlpmodel.predict(movie_vector)\n",
    "    ones = pd.value_counts(pred).filter(items=[1])[1]\n",
    "    zeros = pd.value_counts(pred).filter(items=[0])[0]\n",
    "    positive_perc = round(ones/(ones+zeros)*100,2)\n",
    "    return positive_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "testpred = np.array([0,0,0])\n",
    "ones = pd.value_counts(testpred).filter(items=[1])\n",
    "zeros = pd.value_counts(testpred).filter(items=[0])\n",
    "ones\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-47c36108ebcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0;34m\"The truth value of a {0} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\".format(\n\u001b[0;32m-> 1555\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m             )\n\u001b[1;32m   1557\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "if not zeros:\n",
    "    print(\"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         comb_review user_sentiment_code  \\\n",
      "3  disappointed i read through the reviews on her...            negative   \n",
      "4  irritation my husband bought this gel for us. ...            negative   \n",
      "5  not worth it my boyfriend and i bought this to...            negative   \n",
      "6  disappointing bought this earlier today and wa...            negative   \n",
      "7  not happy at all i bought this product for my ...            negative   \n",
      "\n",
      "                       product_name  \n",
      "3  k-y love sensuality pleasure gel  \n",
      "4  k-y love sensuality pleasure gel  \n",
      "5  k-y love sensuality pleasure gel  \n",
      "6  k-y love sensuality pleasure gel  \n",
      "7  k-y love sensuality pleasure gel  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.48"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result  = predict_Sentiment(\"k-y love sensuality pleasure gel\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(pred).filter(items=[1])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(pred).filter(items=[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
